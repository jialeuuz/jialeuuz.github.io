[
  {
    "objectID": "interests.html",
    "href": "interests.html",
    "title": "Research Interests",
    "section": "",
    "text": "My research centers on large language models (LLMs) and applied NLP. Below I expand on the potential research topics from my CV and the concrete questions/methods I’m pursuing."
  },
  {
    "objectID": "interests.html#humanllm-interaction-under-underspecification",
    "href": "interests.html#humanllm-interaction-under-underspecification",
    "title": "Research Interests",
    "section": "Human–LLM Interaction under Underspecification",
    "text": "Human–LLM Interaction under Underspecification\n\nGoal: Make LLMs proactively surface missing constraints, ask clarifying questions, and avoid over-eager compliance when the task is ill-posed.\nMethods: rubric-based/verifiable reward training (e.g., RL with verifiable rubrics), critique–refine loops, refusal calibration, and uncertainty-aware prompting.\nData & Evaluation: realistic, noisy user prompts; multi-turn workflows; verifiable checklists; human and automatic evaluators with clear datacards and bias/contamination checks."
  },
  {
    "objectID": "interests.html#agent-based-llms-and-multi-step-reasoning",
    "href": "interests.html#agent-based-llms-and-multi-step-reasoning",
    "title": "Research Interests",
    "section": "Agent-based LLMs and Multi-step Reasoning",
    "text": "Agent-based LLMs and Multi-step Reasoning\n\nGoal: Improve reliability and sample efficiency of tool-using, planning, and self-verifying agents.\nMethods: hierarchical plans, verifier/solver architectures, think-prefix optimization, selective self-reflection, and lightweight tree/graph-of-thought with early stopping.\nEvaluation: grounded tasks with objective end states (QA+tools, coding with tests, retrieval with citations), latency–cost–quality trade-off analysis."
  },
  {
    "objectID": "interests.html#data-flywheels-and-self-improving-systems",
    "href": "interests.html#data-flywheels-and-self-improving-systems",
    "title": "Research Interests",
    "section": "Data Flywheels and Self-improving Systems",
    "text": "Data Flywheels and Self-improving Systems\n\nGoal: Close the loop from SFT → eval → generation → filtering → retraining to continuously improve models and tests.\nMethods: automatic curriculum building, difficulty-aware sampling, deduplication and contamination control, safety/PII gating, and feedback-driven rubric updates.\nTooling: reproducible eval harnesses, dataset versioning, and dashboards tracking quality, cost, and drift."
  },
  {
    "objectID": "interests.html#interpretability-safety-and-controllability",
    "href": "interests.html#interpretability-safety-and-controllability",
    "title": "Research Interests",
    "section": "Interpretability, Safety, and Controllability",
    "text": "Interpretability, Safety, and Controllability\n\nGoal: Better understand, steer, and safeguard LLM behavior in real deployments.\nMethods: feature-level probing and sparse representations, policy shaping via refusal/critique heads, jailbreak/over-alignment audits, and guardrailed tool-use.\nInterfaces: system prompt design, capability scoping, and safe fallback strategies when detectors/verifiers disagree."
  },
  {
    "objectID": "interests.html#evaluation-and-benchmarks-realistic-even-if-dumb",
    "href": "interests.html#evaluation-and-benchmarks-realistic-even-if-dumb",
    "title": "Research Interests",
    "section": "Evaluation and Benchmarks (“Realistic, Even if ‘Dumb’”)",
    "text": "Evaluation and Benchmarks (“Realistic, Even if ‘Dumb’”)\n\nGoal: Build evaluations that reflect messy real-world tasks rather than only cherry-picked leaderboards.\nMethods: coverage-driven test sets, prompt-variance robustness, out-of-distribution and adversarial stress tests, and verifiable pass/fail criteria.\nReporting: cost/latency alongside accuracy, provenance tracking, contamination checks, and transparent error taxonomies.\n\nIf you’re interested in collaborating, feel free to reach out: jialeuuz@gmail.com."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization — co-first author (equal contribution; not first-listed). AACL 2025 via ARR (ARR average score: 3.5; plan to resubmit to ACL 2025 after revisions). Contribution highlights: designed experiments and framework, integrated explainability into iterative algorithms, wrote appendix and contributed to main text.\nDecoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment — third author. Under review. Released accompanying open dataset ExpressiveSpeech on Hugging Face. Project page: https://freedomintelligence.github.io/ExpressiveSpeech/.\nBreaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning — sixth author. ICLR under review."
  },
  {
    "objectID": "publications.html#under-review",
    "href": "publications.html#under-review",
    "title": "Publications",
    "section": "",
    "text": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization — co-first author (equal contribution; not first-listed). AACL 2025 via ARR (ARR average score: 3.5; plan to resubmit to ACL 2025 after revisions). Contribution highlights: designed experiments and framework, integrated explainability into iterative algorithms, wrote appendix and contributed to main text.\nDecoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment — third author. Under review. Released accompanying open dataset ExpressiveSpeech on Hugging Face. Project page: https://freedomintelligence.github.io/ExpressiveSpeech/.\nBreaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning — sixth author. ICLR under review."
  },
  {
    "objectID": "publications.html#in-progress",
    "href": "publications.html#in-progress",
    "title": "Publications",
    "section": "In Progress",
    "text": "In Progress\n\nEnabling LLM to Ask — first author. We analyze why LLMs answer incorrectly along three dimensions: (1) missing or ambiguous user intent, (2) overconfident user queries, and (3) the model forcing explanations when it does not know. We validate the effectiveness of targeted clarifications with controlled experiments and a new benchmark (askBench). Based on these dimensions, we design a data‑construction pipeline that teaches models to: clarify to elicit intent, clarify to correct user errors, and clarify to acknowledge/cope with limitations. Training via RLVR yields strong generalization and asking ability while maintaining base capabilities (with slight gains in some domains). Collaboration with Prof. Lu Cheng (UIC).\nRubricsHub: Automatically Generating High-quality General Rubrics — second author; internship work at Li Auto. Defines Meta‑Rubric criteria and an automated generation–evaluation–feedback pipeline to create high‑quality, domain‑general rubric data. Compiles rubrics into executable graders for calibrated scoring and feedback; applied to SFT filtering, DPO pair construction, and RL reward modeling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jiale Zhao",
    "section": "",
    "text": "jialeuuz@gmail.com\n  \n  \n    \n     jialeuuz\n  \n  \n    \n     CV\n  \n\n  \n  \nHi! I’m Jiale Zhao, a computer science graduate (B.Eng., 2025) from Chongqing University of Posts and Telecommunications. I currently work on rubric‑based RL for large language models during my internship at Li Auto.\nI plan to begin a PhD in Fall 2026. My interests center on large language models and applied NLP, including:\n\nHuman–LLM interaction: clarifying questions, underspecification, and intent elicitation\nAgent-based LLMs and multi-step reasoning\nRubric-based RL\nData flywheels and self-improving systems\nInterpretability and controllability\n\n\n\n\nFall 2026 (planned): PhD studies (applications in progress)\nSep 2021 – Jun 2025: B.Eng., Computer Science, Chongqing University of Posts and Telecommunications\n\n\n\n\n\nThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization — co-first author (equal contribution; not first-listed). Under review via ARR for AACL 2025 (ARR average score: 3.5; planning resubmission to ACL 2025 after revisions).\nDecoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment — third author; under review. Dataset: ExpressiveSpeech on Hugging Face.\nBreaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning — sixth author. ICLR under review.\n\n\n\n\n\nEnabling LLM to Ask — first author; clarifying‑question capability across missing/ambiguous intent, overconfident user queries, and unknowns; validated on askBench; trained with RLVR; strong generalization. Ongoing collaboration with Prof. Lu Cheng (UIC).\nRubricsHub: Automatically Generating High-quality General Rubrics — second author; internship work at Li Auto. Meta‑Rubric criteria and an automated pipeline to generate general rubrics compiled into executable graders; used across SFT filtering, DPO pair construction, and RL reward modeling.\n\n\n\n\n\nMindGPTo — an end-to-end multimodal app inspired by GPT‑4o with paralinguistic features; built from scratch with modular design and front/back separation — developed during my internship at Li Auto.\nMulti-step Reasoning + Tool Invocation Agent — constructs SFT data for LLM Q&A, integrates API function calls, and solves complex tasks via multi-step planning — developed during my internship at Li Auto.\nData Flywheel for Code LLM — an iterative framework centered on evaluation to mass-produce high-quality training and test data (SFT → eval → data generation → filtering → back to SFT) — developed during my internship at Li Auto."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Jiale Zhao",
    "section": "",
    "text": "Fall 2026 (planned): PhD studies (applications in progress)\nSep 2021 – Jun 2025: B.Eng., Computer Science, Chongqing University of Posts and Telecommunications"
  },
  {
    "objectID": "index.html#publications",
    "href": "index.html#publications",
    "title": "Jiale Zhao",
    "section": "",
    "text": "ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization — co-first author (equal contribution; not first-listed). Under review via ARR for AACL 2025 (ARR average score: 3.5; planning resubmission to ACL 2025 after revisions).\nDecoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment — third author; under review. Dataset: ExpressiveSpeech on Hugging Face.\nBreaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning — sixth author. ICLR under review."
  },
  {
    "objectID": "index.html#ongoing-work",
    "href": "index.html#ongoing-work",
    "title": "Jiale Zhao",
    "section": "",
    "text": "Enabling LLM to Ask — first author; clarifying‑question capability across missing/ambiguous intent, overconfident user queries, and unknowns; validated on askBench; trained with RLVR; strong generalization. Ongoing collaboration with Prof. Lu Cheng (UIC).\nRubricsHub: Automatically Generating High-quality General Rubrics — second author; internship work at Li Auto. Meta‑Rubric criteria and an automated pipeline to generate general rubrics compiled into executable graders; used across SFT filtering, DPO pair construction, and RL reward modeling."
  },
  {
    "objectID": "index.html#selected-projects",
    "href": "index.html#selected-projects",
    "title": "Jiale Zhao",
    "section": "",
    "text": "MindGPTo — an end-to-end multimodal app inspired by GPT‑4o with paralinguistic features; built from scratch with modular design and front/back separation — developed during my internship at Li Auto.\nMulti-step Reasoning + Tool Invocation Agent — constructs SFT data for LLM Q&A, integrates API function calls, and solves complex tasks via multi-step planning — developed during my internship at Li Auto.\nData Flywheel for Code LLM — an iterative framework centered on evaluation to mass-produce high-quality training and test data (SFT → eval → data generation → filtering → back to SFT) — developed during my internship at Li Auto."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "赵佳乐的个人主页"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Professional Summary\n      \n        Computer Science B.Eng. (2025) focused on LLMs and applied NLP. I currently work on rubric‑based RL during my internship at Li Auto and plan to begin a PhD in Fall 2026. Initiated ML research in a university lab (Freshman), conducted CV research (Sophomore Fall), transitioned to NLP research (Junior Spring), and gained industry experience as an LLM Algorithm Intern at Li Auto (Junior Year+).\n      \n      \n        Key interests: 1) Human–LLM interaction; 2) Agent‑based LLMs and multi‑step reasoning; 3) Rubric‑based RL; 4) Data flywheels & self‑improving systems; 5) Interpretability & controllability.\n      \n    \n\n    \n      Experience\n      \n        \n          \n            LLM Algorithm Intern — Li Auto\n            Sep 2023 – present · Beijing\n          \n          \n            Data Flywheel for Code LLM: Iterative cycle centered on evaluation (SFT → evaluation → data generation → filtering → back to SFT) to mass‑produce high‑quality training and evaluation data.\n            Multi‑step Reasoning + Tool Invocation Agent: Constructed SFT data for LLM Q&A, implemented API function calls, and solved complex reasoning problems through multi‑step processes.\n            MindGPTo: End‑to‑end multimodal app inspired by GPT‑4o with paralinguistic features; built from scratch with modular FE/BE, large‑scale audio data pipelines, and SFT to enhance conversational capabilities.\n          \n        \n      \n    \n\n    \n      Education\n      \n        \n          \n            Chongqing Univ. of Posts and Telecommunications\n            B.Eng., Computer Science · 2021 – 2025 · Chongqing\n          \n          \n            Initiated ML research in a university lab (Freshman), conducted CV research (Sophomore Fall), transitioned to NLP research (Junior Spring), and gained industry experience as an LLM Algorithm Intern at Li Auto (Junior Year).\n          \n        \n      \n    \n\n    \n      Publications (Under Review)\n      \n        ThinkPilot: Steering Reasoning Models via Automated Think‑prefixes Optimization\n        Co‑first author (equal contribution; not first‑listed). AACL 2025 via ARR (ARR average score: 3.5; planning resubmission to ACL 2025 after revisions).\n        \n          Designed experiments and implemented the framework.\n          Integrated explainability into the iterative algorithm.\n          Wrote the appendix and contributed to the main text.\n        \n      \n      \n        Breaking the Exploration Bottleneck: Rubric‑Scaffolded Reinforcement Learning for General LLM Reasoning: Sixth author. ICLR under review.\n        Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment: Third author; under review. Dataset: ExpressiveSpeech on Hugging Face.\n      \n    \n\n    \n      Ongoing Work\n      \n        Enabling LLM to Ask — first author. Clarifying‑question capability across missing/ambiguous intent, overconfident user queries, and unknowns; validated on askBench; trained with RLVR; strong generalization. Collaboration with Prof. Lu Cheng (UIC).\n        RubricsHub: Automatically Generating High‑quality General Rubrics — second author; internship work at Li Auto. Meta‑Rubric criteria and an automated pipeline to generate general rubrics compiled into executable graders; applied to SFT filtering, DPO pair construction, and RL reward modeling.\n      \n    \n\n    \n      Research Directions\n      Agent‑based LLMs — Efficient Complex Problem Solving\n      \n        Many real‑world problems require multi‑source reasoning and dynamic user feedback. I focus on:\n        1) decomposing complex tasks into simpler sub‑tasks; 2) introducing a time‑frame mechanism to\n        accept updates and regularly reflect on progress; 3) coordinating several parallel smaller\n        models (e.g., multiple 7B LLMs) to improve efficiency and accuracy at the same compute cost.\n      \n\n      Self‑Evaluation → Self‑Improvement\n      \n        Observed three failure modes in code tasks: (1) inconsistently solved problems; (2) problems\n        rarely solved spontaneously but solvable with simple hints; (3) problems requiring complex or\n        unattainable guidance. Address via sampling (1), heuristics/self‑guided strategies (2), and\n        iterative evolution (3). Continuous self‑improvement needs large, diverse, fresh data and\n        strong filtering; designing diverse, accurate test queries is often easier than solving tasks,\n        but ensuring correctness and diversity remains a core challenge.\n      \n\n      Human–LLM Interaction — Enabling LLMs to Ask\n      \n        Tackle excessive agreeableness and underspecified queries by enabling models to: recognize and\n        challenge incorrect or contradictory user information; detect and explicitly request missing\n        conditions; and summarize challenges to proactively solicit user assistance for difficult tasks.\n      \n\n      Interpretability & Analysis — Insight → Control → Safety\n      \n        Going beyond surface‑level prompting/defense, I explore using deeper interpretability to\n        understand inner mechanisms and develop more effective control of reasoning. Inspired by work\n        that “overclocks” models with small auxiliary controllers, I consider training control modules\n        from large response corpora to purposefully steer reasoning, improving safety and efficiency.\n      \n\n      Benchmarks & Evaluation — Making Benchmarks “Dumber”\n      \n        Real usage involves incomplete, ambiguous, or verbose queries. I propose transforming single‑\n        turn benchmarks into simulated multi‑turn “user” interactions (introducing omissions, errors,\n        colloquial phrasing). For knowledge domains (e.g., medicine), intentionally vague queries can\n        require elicitation. This better evaluates underspecification handling and intent elicitation.\n      \n\n      Bridging Research & Application\n      \n        I aim to keep academic research connected to real‑world needs—pursuing a PhD and future\n        faculty path while collaborating with industry for practical constraints like compute. The goal\n        is research that meaningfully benefits society."
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "B.Eng., Algorithm Engineering · 2021 – 2025\nInitiated ML research in a university lab (Freshman), conducted computer vision research (Sophomore Fall), transitioned to NLP research (Junior Spring), and gained industry experience as an LLM Algorithm Intern at Li Auto (Junior Year)."
  },
  {
    "objectID": "cv.html#professional-summary",
    "href": "cv.html#professional-summary",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "I have two years of LLM algorithm internship experience, with strong coding and research skills in LLM and multimodal domains. My key interests include agent-based LLMs, data flywheels and self-improving systems, human–LLM interaction, interpretability and analysis, benchmarks and evaluation, and bridging research with real-world applications."
  },
  {
    "objectID": "cv.html#publications-under-review",
    "href": "cv.html#publications-under-review",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Submitted to AACL 2025 via ARR (with plans to resubmit to ACL 2025 after revisions based on reviews).\nPersonal contributions\n\nDesigned experiments and implemented the framework.\nIntroduced explainability methods into the iterative algorithm.\nWrote the appendix and contributed to the main text."
  },
  {
    "objectID": "cv.html#research-experience",
    "href": "cv.html#research-experience",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Data Flywheel for Code LLM. Built an iterative framework centered on evaluation (SFT → evaluation → training data generation → filtering → back to SFT) to mass-produce high-quality training and evaluation datasets.\nMulti-step Reasoning and Tool Invocation Agent Based on Code LLM. Constructed SFT data for LLM Q&A tasks, implemented API function calls, and solved complex reasoning problems through multi-step processes.\nMindGPTo. Developed an end-to-end multimodal application that replicates much of GPT-4O’s functionality while incorporating unique paralinguistic features.\n\nBuilt MindGPTo from scratch with a modular design and separated front-end/back-end.\nEstablished large-scale audio data pipelines and performed SFT to enhance conversational and anthropomorphic capabilities."
  },
  {
    "objectID": "cv.html#research-directions-and-ideas",
    "href": "cv.html#research-directions-and-ideas",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Many real-world problems require reasoning across multiple sources and dynamically incorporating user feedback (for example, planning a weekend trip to Beijing). My ideas:\n\nDecompose complex tasks into simpler sub-tasks that can be handled more efficiently.\nIntroduce a time-frame mechanism to accept user updates and regularly reflect on an agent’s progress.\nCoordinate multiple parallel smaller models (e.g., several 7B LLMs) to achieve higher efficiency and accuracy compared to a single large model at similar compute.\n\n\n\n\nDuring early internship work on LLMs for code generation, I observed that models often reach correct solutions after receiving additional guidance. I identified three failure modes: (1) inconsistently solved problems; (2) problems solvable via simple hints; and (3) problems that need complex or currently unattainable guidance. The first type can be addressed via increased sampling, the second via heuristics or self-guided strategies, and the third via iterative evolution without external models. Continuous self-improvement, however, demands large, diverse data and rigorous filtering, along with fresh and challenging benchmarks.\n\n\n\nLLMs are often overly agreeable, fail to request clarification, and rarely solicit missing information from users. My goals are to help models: (1) challenge incorrect or contradictory user statements; (2) detect underspecified queries and ask for missing conditions; and (3) summarize key challenges for hard tasks and proactively seek user assistance.\n\n\n\nExploring thought-chain interpretability highlighted safety issues. Most attack and defense methods focus on surface cues. I aim to use deep interpretability to understand internal mechanisms, enabling safer control and more efficient vulnerability testing. Inspired by work that trains small auxiliary models to “overclock” LLMs without modifying their weights, I am investigating whether comprehensive query sets and response analyses can train control modules that guide reasoning processes.\n\n\n\nCurrent benchmarks are unrealistically “smart”—queries are concise, fully specified, and unambiguous. Real user input is often incomplete, ambiguous, or verbose. I propose transforming standard benchmarks into multi-turn, underspecified “dumber” variants that simulate true user interactions. Logic-heavy tasks (math, code) would introduce errors or omit conditions, while knowledge tasks would include vague or incomplete scenarios, compelling LLMs to clarify needs before solving problems.\n\n\n\nExperiences across academia and industry strengthened my commitment to bridge research with practical needs. I plan to pursue a PhD, seek a faculty position, and cultivate collaborations or entrepreneurial efforts that overcome real-world constraints (such as compute). The ultimate goal is to ensure that AI research remains meaningfully connected to societal benefit."
  },
  {
    "objectID": "cv.html#additional-publications-and-datasets",
    "href": "cv.html#additional-publications-and-datasets",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment. Second author, currently under review. arXiv:2510.20513.\nExpressiveSpeech Dataset. High-quality bilingual (Chinese–English) expressive speech dataset (~51h, ~14k utterances) curated with DeEAR. Hugging Face · Project page."
  },
  {
    "objectID": "cv.html#updating-or-exporting-this-cv",
    "href": "cv.html#updating-or-exporting-this-cv",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Edit this cv.qmd file directly to update content. Run quarto render cv.qmd for HTML output, or quarto render cv.qmd --to pdf if a PDF export is needed."
  }
]