---
title: "Publications"
editor:
  markdown:
    wrap: 72
---

## Overview

I work on large language models and applied NLP, with a focus on agentic systems, self-improving pipelines, and realistic evaluation.

## Under Review

- **[Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment](https://arxiv.org/abs/2510.20513)** — second author. Under review. Released accompanying open dataset **ExpressiveSpeech** on Hugging Face: <https://huggingface.co/datasets/FreedomIntelligence/ExpressiveSpeech>. Project page: <https://freedomintelligence.github.io/ExpressiveSpeech/>.

- **[ThinkPilot: Steering Reasoning Models via Automated Think-prefixes Optimization](https://www.arxiv.org/abs/2510.12063)** — co-first author (equal contribution; not first-listed). AACL 2025 via ARR (ARR average score: 3.5; plan to resubmit to ACL 2025 after revisions). Contribution highlights: designed experiments and framework, integrated explainability into iterative algorithms, wrote appendix and contributed to main text.

## In Progress

- Enabling LLM to Ask — an end-to-end pipeline to enable LLMs to ask clarifying questions; includes askBench benchmark, training‑data construction methodology and dataset; trained via RLVR; collaboration with Prof. Lu Cheng (UIC).

## Working Notes & Directions

- Agent-based LLMs for efficient complex problem solving
- Self-evaluation → self-improvement via robust data flywheels
- Human–LLM interaction: eliciting missing info and handling underspecification
- Interpretability, controllability, and safety-through-analysis
- “Dumber” benchmarks that better reflect real-world usage

## Links

- [GitHub](https://github.com/jialeuuz) — code experiments and supporting materials.
- [Email](mailto:jialeuuz@gmail.com) — reach out if you’d like to collaborate.
