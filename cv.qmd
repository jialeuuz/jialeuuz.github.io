---
title: ""
page-layout: full
body-classes: page-cv
format:
  html:
    toc: false
    theme: [cosmo, styles.scss]
    css: custom.css
    include-in-header:
      text: |
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous" referrerpolicy="no-referrer"/>
---

::: {.content-visible when-format=html}
```{=html}
<div class="cv cv-single">
  <main class="cv-content">
    <section class="cv-section">
      <h2>Professional Summary</h2>
      <p>
        Computer Science B.Eng. (2025) focused on LLMs and applied NLP. I currently work on rubric‑based RL during my internship at Li Auto and plan to begin a PhD in Fall 2026. Initiated ML research in a university lab (Freshman), conducted CV research (Sophomore Fall), transitioned to NLP research (Junior Spring), and gained industry experience as an LLM Algorithm Intern at Li Auto (Junior Year+).
      </p>
      <p>
        Key interests: 1) Human–LLM interaction; 2) Agent‑based LLMs and multi‑step reasoning; 3) Rubric‑based RL; 4) Data flywheels & self‑improving systems; 5) Interpretability & controllability.
      </p>
    </section>

    <section class="cv-section">
      <h2>Experience</h2>
      <div class="cv-timeline">
        <article class="cv-item">
          <header class="cv-item-header">
            <h3>LLM Algorithm Intern — Li Auto</h3>
            <span class="cv-item-meta">Sep 2023 – present · Beijing</span>
          </header>
          <ul>
            <li><strong>Data Flywheel for Code LLM:</strong> Iterative cycle centered on evaluation (SFT → evaluation → data generation → filtering → back to SFT) to mass‑produce high‑quality training and evaluation data.</li>
            <li><strong>Multi‑step Reasoning + Tool Invocation Agent:</strong> Constructed SFT data for LLM Q&A, implemented API function calls, and solved complex reasoning problems through multi‑step processes.</li>
            <li><strong>MindGPTo:</strong> End‑to‑end multimodal app inspired by GPT‑4o with paralinguistic features; built from scratch with modular FE/BE, large‑scale audio data pipelines, and SFT to enhance conversational capabilities.</li>
          </ul>
        </article>
      </div>
    </section>

    <section class="cv-section">
      <h2>Education</h2>
      <div class="cv-timeline">
        <article class="cv-item">
          <header class="cv-item-header">
            <h3>Chongqing Univ. of Posts and Telecommunications</h3>
            <span class="cv-item-meta">B.Eng., Computer Science · 2021 – 2025 · Chongqing</span>
          </header>
          <p>
            Initiated ML research in a university lab (Freshman), conducted CV research (Sophomore Fall), transitioned to NLP research (Junior Spring), and gained industry experience as an LLM Algorithm Intern at Li Auto (Junior Year).
          </p>
        </article>
      </div>
    </section>

    <section class="cv-section">
      <h2>Publications (Under Review)</h2>
      <article class="cv-item">
        <h3><a href="https://www.arxiv.org/abs/2510.12063">ThinkPilot: Steering Reasoning Models via Automated Think‑prefixes Optimization</a></h3>
        <p>Co‑first author (equal contribution; not first‑listed). AACL 2025 via ARR (ARR average score: 3.5; planning resubmission to ACL 2025 after revisions).</p>
        <ul>
          <li>Designed experiments and implemented the framework.</li>
          <li>Integrated explainability into the iterative algorithm.</li>
          <li>Wrote the appendix and contributed to the main text.</li>
        </ul>
      </article>
      <ul class="cv-bullets">
        <li><strong><a href="https://www.arxiv.org/abs/2508.16949">Breaking the Exploration Bottleneck: Rubric‑Scaffolded Reinforcement Learning for General LLM Reasoning</a>:</strong> Sixth author. ICLR under review.</li>
        <li><strong><a href="https://www.arxiv.org/abs/2510.20513">Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment</a>:</strong> Third author; under review. Dataset: <a href="https://huggingface.co/datasets/FreedomIntelligence/ExpressiveSpeech">ExpressiveSpeech</a> on Hugging Face.</li>
      </ul>
    </section>

    <section class="cv-section">
      <h2>Ongoing Work</h2>
      <ul class="cv-bullets">
        <li><strong>Enabling LLM to Ask</strong> — first author. Clarifying‑question capability across missing/ambiguous intent, overconfident user queries, and unknowns; validated on askBench; trained with RLVR; strong generalization. Collaboration with Prof. Lu Cheng (UIC).</li>
        <li><strong>RubricsHub: Automatically Generating High‑quality General Rubrics</strong> — second author; internship work at Li Auto. Meta‑Rubric criteria and an automated pipeline to generate general rubrics compiled into executable graders; applied to SFT filtering, DPO pair construction, and RL reward modeling.</li>
      </ul>
    </section>

    <section class="cv-section">
      <h2>Research Directions</h2>
      <h3>Agent‑based LLMs — Efficient Complex Problem Solving</h3>
      <p>
        Many real‑world problems require multi‑source reasoning and dynamic user feedback. I focus on:
        1) decomposing complex tasks into simpler sub‑tasks; 2) introducing a time‑frame mechanism to
        accept updates and regularly reflect on progress; 3) coordinating several parallel smaller
        models (e.g., multiple 7B LLMs) to improve efficiency and accuracy at the same compute cost.
      </p>

      <h3>Self‑Evaluation → Self‑Improvement</h3>
      <p>
        Observed three failure modes in code tasks: (1) inconsistently solved problems; (2) problems
        rarely solved spontaneously but solvable with simple hints; (3) problems requiring complex or
        unattainable guidance. Address via sampling (1), heuristics/self‑guided strategies (2), and
        iterative evolution (3). Continuous self‑improvement needs large, diverse, fresh data and
        strong filtering; designing diverse, accurate test queries is often easier than solving tasks,
        but ensuring correctness and diversity remains a core challenge.
      </p>

      <h3>Human–LLM Interaction — Enabling LLMs to Ask</h3>
      <p>
        Tackle excessive agreeableness and underspecified queries by enabling models to: recognize and
        challenge incorrect or contradictory user information; detect and explicitly request missing
        conditions; and summarize challenges to proactively solicit user assistance for difficult tasks.
      </p>

      <h3>Interpretability & Analysis — Insight → Control → Safety</h3>
      <p>
        Going beyond surface‑level prompting/defense, I explore using deeper interpretability to
        understand inner mechanisms and develop more effective control of reasoning. Inspired by work
        that “overclocks” models with small auxiliary controllers, I consider training control modules
        from large response corpora to purposefully steer reasoning, improving safety and efficiency.
      </p>

      <h3>Benchmarks & Evaluation — Making Benchmarks “Dumber”</h3>
      <p>
        Real usage involves incomplete, ambiguous, or verbose queries. I propose transforming single‑
        turn benchmarks into simulated multi‑turn “user” interactions (introducing omissions, errors,
        colloquial phrasing). For knowledge domains (e.g., medicine), intentionally vague queries can
        require elicitation. This better evaluates underspecification handling and intent elicitation.
      </p>

      <h3>Bridging Research & Application</h3>
      <p>
        I aim to keep academic research connected to real‑world needs—pursuing a PhD and future
        faculty path while collaborating with industry for practical constraints like compute. The goal
        is research that meaningfully benefits society.
      </p>
    </section>
    
  </main>
</div>
```
:::
