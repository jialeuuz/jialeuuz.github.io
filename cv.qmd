---
title: "Jiale Zhao — CV"
author:
  firstname: Jiale
  lastname: Zhao
  position: "LLM Algorithm Intern"
  contacts:
    - icon: fa envelope
      text: jialeuuz@gmail.com
      url: mailto:jialeuuz@gmail.com
    - icon: fa brands github
      text: jialeuuz
      url: https://github.com/jialeuuz
    - icon: fa house
      text: jialeuuz.github.io
      url: https://jialeuuz.github.io
format: awesomecv-typst
brand:
  typography:
    fonts:
      - family: Roboto
        source: google
        weight: [100, 400, 700]
      - family: Source Sans 3
        source: google
        weight: [100, 400, 700]
        style: [normal, italic]
    base: Source Sans 3
  color:
    primary: "#5B8DEF"
    link: "#1F2937"
---

## Summary

I am a Computer Science B.Eng. student (2025) at Chongqing Univ. of Posts and Telecommunications and an LLM algorithm intern at Li Auto. I currently work on rubric‑based RLVR and “Enabling LLM to Ask” with Prof. Lu Cheng (UIC).

My interests include **human‑centered HCI**, **agentic/multi‑step reasoning**, **interpretability/controllability**, **self‑evolving systems**, and **multimodal pipelines**.

## Education

```{=typst}
#resume-entry(title: [B.Eng., Computer Science],location: [Chongqing, China],date: [2021 – 2025],description: [Chongqing Univ. of Posts and Telecommunications],)
```

## Publications (Under Review)

```{=typst}
#resume-item[
- **ThinkPilot: Steering Reasoning Models via Automated Think‑prefixes Optimization** (co‑first; AACL 2025 via ARR; ARR avg score: 3.5; planning ACL 2025 resubmission)
- **Decoding the Ear: Objectifying Expressiveness from Human Preference Through Efficient Alignment** (third; ICASSP under review)
- **Breaking the Exploration Bottleneck: Rubric‑Scaffolded RL for General LLM Reasoning** (sixth; ICLR under review)
]
```

## Ongoing Work

```{=typst}
#resume-item[
- **Enabling LLM to Ask** — first‑author work analyzing three failure modes (missing/ambiguous intent, overconfident queries, forced answers), building askBench, and training with RLVR to elicit clarifying questions while retaining base skills (with Prof. Lu Cheng, UIC)
- **RubricsHub** — Meta‑Rubric criteria plus automated generate‑evaluate‑feedback loop to build high‑quality, domain‑general rubrics compiled into executable graders for SFT filtering, DPO pair building, and RL reward modeling (Li Auto)
]
```

## Experience

```{=typst}
#resume-entry(title: [LLM Algorithm Intern],location: [Li Auto, Beijing],date: [Sep 2023 – present],description: [
- Data Flywheel for Code LLM: Evaluation‑centered loop (SFT → eval → data → filtering → SFT) to mass‑produce high‑quality training/eval data.
- Multi‑step Reasoning + Tool Invocation Agent: SFT data for LLM Q&A; API function‑call integration; complex task solving via planning.
- MindGPTo: End‑to‑end multimodal app (GPT‑4o‑inspired) with paralinguistic features; modular FE/BE; large‑scale audio pipelines; SFT.
],)
#resume-entry(title: [Research Experience],location: [China],date: [Before college – present],description: [
- Before college: self‑taught coding and built small projects before entering university.
- Freshman year: joined my first NLP lab via selection; worked mostly independently due to limited advising.
- Freshman summer: joined a second, CV‑focused lab with weekly meetings and structured deep‑learning training; gained a rigorous foundation.
- Sophomore year: still in the CV lab; limited compute blocked transformer experiments, so I focused on reading papers and designing experiments on paper.
- Sophomore spring: moved to a third lab to build “digital humans” and shipped a 24/7 virtual‑avatar livestream on Bilibili.
- Junior to now: Li Auto LLM internship and multiple papers; focusing on rubric‑based RL/RLVR, agentic reasoning, and data‑centric LLM improvement.
],)
```
