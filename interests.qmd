---
title: "Research Interests"
---

My research centers on large language models (LLMs) and applied NLP. Below I expand on the potential research topics from my CV and the concrete questions/methods I’m pursuing.

## Human–LLM Interaction under Underspecification

- Goal: Make LLMs proactively surface missing constraints, ask clarifying questions, and avoid over-eager compliance when the task is ill-posed.
- Methods: rubric-based/verifiable reward training (e.g., RL with verifiable rubrics), critique–refine loops, refusal calibration, and uncertainty-aware prompting.
- Data & Evaluation: realistic, noisy user prompts; multi-turn workflows; verifiable checklists; human and automatic evaluators with clear datacards and bias/contamination checks.

## Agent-based LLMs and Multi-step Reasoning

- Goal: Build code-LLM agents that decompose complex tasks, generate executable plans, and call functions/APIs for real-world interaction.
- Methods: multi-step reasoning for code correction and long-context synthesis, hierarchical planners+critics, deliberate think-prefixes, and integration with execution sandboxes/function-calling APIs for precise grounding.
- Evaluation: QA with tools, coding tasks with unit tests, retrieval with citations, plus latency–cost–quality trade-offs and ablations on plan depth/tool latency.

## Data Flywheels and Self-improving Systems

- Goal: Close the loop from SFT → evaluate → data construct → filter → back to SFT so code LLMs improve with every iteration.
- Methods: evaluation-first mindset (harder specs, rubricized harnesses) to fix today’s noisy/too-easy code eval; evaluation, generation, and filtering share infra so feedback on difficulty directly shapes new data while filtering tools also repair poor samples.
- Tooling: reproducible eval/testbeds, rubric-driven graders for filtering, dataset versioning, and dashboards tracking difficulty, acceptance, and regression risk.

## MindGPTo: End-to-end Multimodal Interaction

- Goal: Deliver GPT-4o-like, audio-centric experiences with controllable paralinguistic traits plus multimodal perception.
- Architecture: Built MindGPTo from scratch with a modular front/back split; supports audio→ASR→LLM→TTS, a lean audio2text mainline, fully end-to-end audio2audio, and audio+image+video→text→TTS.
- Data & SFT: Large-scale audio pipelines mass-produce supervision to boost conversationality and nuanced cues (age, gender, compound emotions, emotional actions, ambient noise), going beyond basic laughter/pause control.



## Interpretability, Safety, and Controllability

- Goal: Better understand, steer, and safeguard LLM behavior in real deployments.
- Methods: feature-level probing and sparse representations, policy shaping via refusal/critique heads, jailbreak/over-alignment audits, and guardrailed tool-use.
- Interfaces: system prompt design, capability scoping, and safe fallback strategies when detectors/verifiers disagree.

## Evaluation and Benchmarks (“Realistic, Even if ‘Dumb’”)

- Goal: Build evaluations that reflect messy real-world tasks rather than only cherry-picked leaderboards.
- Methods: coverage-driven test sets, prompt-variance robustness, out-of-distribution and adversarial stress tests, and verifiable pass/fail criteria.
- Reporting: cost/latency alongside accuracy, provenance tracking, contamination checks, and transparent error taxonomies.

If you’re interested in collaborating, feel free to reach out: jialeuuz@gmail.com.
